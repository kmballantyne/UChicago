{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Pandas Practice and Data Wrangling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will provide hand-on practice with data manipulation using `pandas`.\n",
    "\n",
    "In this lab you will see some examples of some commonly used data wrangling tools in Python. In particular, we aim to give you some familiarity with:\n",
    "\n",
    "* Slicing data frames\n",
    "* Filtering data\n",
    "* Grouped counts\n",
    "* Joining two tables\n",
    "* NA/Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below produces the data frames used in the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = pd.DataFrame(\n",
    "    data={'color': ['red', 'green', 'black', \n",
    "                    'blue', 'black', 'red'],\n",
    "          'first_seen_on': ['a', 'a', 'f', 'a', 'a', 'f'],\n",
    "          'first_season': [2, 1, 2, 3, 3, 1]},\n",
    "    index=['flash', 'arrow', 'vibe', \n",
    "           'atom', 'canary', 'firestorm']\n",
    ")\n",
    "\n",
    "identities = pd.DataFrame(\n",
    "    data={'ego': ['barry allen', 'oliver queen', 'cisco ramon',\n",
    "                  'ray palmer', 'sara lance', \n",
    "                  'martin stein', 'ronnie raymond'],\n",
    "          'alter-ego': ['flash', 'arrow', 'vibe', 'atom',\n",
    "                        'canary', 'firestorm', 'firestorm']}\n",
    ")\n",
    "\n",
    "teams = pd.DataFrame(\n",
    "    data={'team': ['flash', 'arrow', 'flash', 'legends', \n",
    "                   'flash', 'legends', 'arrow'],\n",
    "          'hero': ['flash', 'arrow', 'vibe', 'atom', \n",
    "                   'killer frost', 'firestorm', 'speedy']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the examples that follow, we will be using a toy data set containing information about superheroes in the Arrowverse.  In the `first_seen_on` column, `a` stands for Archer and `f`, Flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice and Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column selection by label\n",
    "To select a column of a `DataFrame` by column label, the safest and fastest way is to use the `.loc` method. General usage looks like `frame.loc[rowname,colname]`. (Reminder that the colon `:` means \"everything\").  For example, if we want the `color` column of the `ex` data frame, we would use :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.loc[:, 'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting multiple columns is easy.  You just need to supply a list of column names.  Here we select the `color` and `value` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.loc[:, ['color', 'first_season']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `.loc` is invaluable when writing production code, it may be a little too verbose for interactive use.  One recommended alternative is the `[]` method, which takes on the form `frame['colname']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes['first_seen_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row Selection by Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we want to select a row by its label, we can use the same `.loc` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.loc[['flash', 'vibe'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want all the columns returned, we can, for brevity, drop the colon without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.loc[['flash', 'vibe']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Selection by Label\n",
    "\n",
    "More generally you can slice across both rows and columns at the same time.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.loc['flash':'atom', :'first_seen_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection by Integer Index\n",
    "\n",
    "If you want to select rows and columns by position, the Data Frame has an analogous `.iloc` method for integer indexing. Remember that Python indexing starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.iloc[:4,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with boolean arrays\n",
    "Filtering is the process of removing unwanted material.  In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, culling out fishy outliers, or analyzing subgroups of your data set.  For example, we may be interested in characters that debuted in season 3 of Archer.  Note that compound expressions have to be grouped with parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes[(heroes['first_season']==3) & (heroes['first_seen_on']=='a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Solving Strategy\n",
    "We want to highlight the strategy for filtering to answer the question above:\n",
    "\n",
    "* **Identify the variables of interest**\n",
    "    * Interested in the debut: `first_season` and `first_seen_on`\n",
    "* **Translate the question into statements one with True/False answers**\n",
    "    * Did the hero debut on Archer? $\\rightarrow$ The hero has `first_seen_on` equal to `a`\n",
    "    * Did the hero debut in season 3? $\\rightarrow$ The hero has `first_season` equal to `3`\n",
    "* **Translate the statements into boolean statements**\n",
    "    * The hero has `first_seen_on` equal to `a` $\\rightarrow$ `hero['first_seen_on']=='a'`\n",
    "    * The hero has `first_season` equal to `3` $\\rightarrow$ `heroes['first_season']==3`\n",
    "* **Use the boolean array to filter the data**\n",
    "\n",
    "Note that compound expressions have to be grouped with parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning \n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    ">=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An often-used operation missing from the above table is a test-of-membership.  The `Series.isin(values)` method returns a boolean array denoting whether each element of `Series` is in `values`.  We can then use the array to subset our data frame. For example, if we wanted to see which rows of `heroes` had values in $\\{1,3\\}$, we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes[heroes['first_season'].isin([1,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in both examples above, the expression in the brackets evaluates to a boolean series.  The general strategy for filtering data frames, then, is to write an expression of the form `frame[logical statement]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of instances of a value in a `Series`, we can use the `value_counts` method.  Below we count the number of instances of each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes['color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated analysis might involve counting the number of instances a tuple appears.  Here we count $(color,value)$ tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.groupby(['color', 'first_season']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a series that has been multi-indexed.  We'll eschew this topic for now.  To get a data frame back, we'll use the `reset_index` method, which also allows us to simulataneously name the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.groupby(['color', 'first_season']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Tables on One Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have another table that classifies superheroes into their respective teams.  Note that `canary` is not in this data set and that `killer frost` and `speedy` are additions that aren't in the original `heroes` set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of the example, we'll convert the index of the `heroes` data frame into an explicit column called `hero`.  A careful examination of the [documentation](http://pandas.pydata.org/pandas-docs/version/0.19.1/generated/pandas.DataFrame.merge.html) will reveal that joining on a mixture of the index and columns is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes['hero'] = heroes.index\n",
    "heroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner join below returns rows representing the heroes that appear in both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='inner', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left and right join\n",
    "The left join returns rows representing heroes in the `ex` (\"left\") data frame, augmented by information found in the `teams` data frame.  Its counterpart, the right join, would return heroes in the `teams` data frame.  Note that the `team` for hero `canary` is an `NaN` value, representing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='left', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer join\n",
    "\n",
    "An outer join on `hero` will return all heroes found in both the left and right data frames.  Any missing values are filled in with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='outer', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More than one match?\n",
    "\n",
    "If the values in the columns to be matched don't uniquely identify a row, then a cartesian product is formed in the merge.  For example, notice that `firestorm` has two different egos, so information from `heroes` had to be duplicated in the merge, once for each ego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, identities, how='inner', \n",
    "         left_on='hero', right_on='alter-ego')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "As shown in lecture, there are a multitude of reasons why a data set might have missing values.  The current implementation of Pandas uses the numpy NaN to represent these null values (older implementations even used `-inf` and `inf`).  Future versions of Pandas might implement a true `null` value---keep your eyes peeled for this in updates!  More information can be found (http://pandas.pydata.org/pandas-docs/stable/missing_data.html)[here].\n",
    "\n",
    "Because of the specialness of missing values, they merit their own set of tools.  For this lab, we will focus on detection.  For replacement, see the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.nan\n",
    "y = pd.merge(heroes, teams, how='outer', on='hero')['first_season']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if a value is null, we use the `isnull()` method for series and data frames.  Alternatively, there is a `pd.isnull()` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull() # won't work since x is neither a series nor a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since filtering out missing data is such a common operation, Pandas also has conveniently included the analogous `notnull()` methods and function for improved human readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Practice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the \"complete\" data set shown below.  Note that the rows are indexed by the superheroes' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_complete = pd.merge(heroes, identities, left_on='hero', right_on='alter-ego')\n",
    "heroes_complete = pd.merge(heroes_complete, teams, how='outer', on='hero')\n",
    "heroes_complete.set_index('hero', inplace=True)\n",
    "heroes_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** What are the outputs of the following calls?  State what is wrong with the ones that will produce errors and propose a fix.  To challenge yourself, try to do this exercise without running any commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.1\n",
    "heroes_complete[flash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the corrected code below:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "'Flash' is a value in the table and must be enclosed in a quotes as a string.\n",
    "<pre>\n",
    "heroes_complete.loc['flash']\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.2\n",
    "heroes_complete[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the corrected code below:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "heroes_complete.iloc[1, 3:5]\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.3\n",
    "heroes_complete.loc['first_seen_on':'team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the corrected code below:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "Selecting by column value needs to be on the second axis\n",
    "<pre>\n",
    "heroes_complete.loc[:, 'first_seen_on':'team']\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_complete.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_complete.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_complete.loc[heroes_complete['color'].isin(['red', 'black'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.4\n",
    "heroes_complete.loc[1, 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the corrected code below:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "heroes_complete.ix[1, 'color'] \n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_complete[heroes_complete['first_season'] % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.5\n",
    "heroes_complete[heroes_complete['color'] == np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the corrected code below:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "NaN cannot be tested with an equality expression, use isnull() instead\n",
    "<pre>\n",
    "heroes_complete[heroes_complete['color'].isnull()]\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Set 2\n",
    "The practice problems below use the department of transportation's \"On-Time\" flight data for all flights originating from SFO or OAK in January 2016.  Information about the variables can be found in the `readme.html` file.  Information about the airports and flights are contained in the comma-delimited files `airports.dat` and `flights.dat`, respectively.  Both were sourced from http://openflights.org/data.html\n",
    "\n",
    "Disclaimer: There is a more direct way of dealing with time data that is not presented in these problems.  This activity is merely an academic exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>carrier</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>flight</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>actual_dep_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>actual_arr_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3FLAA</td>\n",
       "      <td>208</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "      <td>630.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3APAA</td>\n",
       "      <td>208</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "      <td>600.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>1401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3DNAA</td>\n",
       "      <td>208</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "      <td>630.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3FGAA</td>\n",
       "      <td>208</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "      <td>630.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>AA</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>208</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "      <td>640.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day        date carrier tailnum  flight origin destination  \\\n",
       "0  2016      1    1  2016-01-01      AA  N3FLAA     208    SFO         MIA   \n",
       "1  2016      1    2  2016-01-02      AA  N3APAA     208    SFO         MIA   \n",
       "2  2016      1    3  2016-01-03      AA  N3DNAA     208    SFO         MIA   \n",
       "3  2016      1    4  2016-01-04      AA  N3FGAA     208    SFO         MIA   \n",
       "4  2016      1    5  2016-01-05      AA  N3KUAA     208    SFO         MIA   \n",
       "\n",
       "   sched_dep_time  actual_dep_time  sched_arr_time  actual_arr_time  \n",
       "0           630.0            628.0          1458.0           1431.0  \n",
       "1           600.0            553.0          1428.0           1401.0  \n",
       "2           630.0            626.0          1458.0           1431.0  \n",
       "3           630.0            626.0          1458.0           1444.0  \n",
       "4           640.0            632.0          1458.0           1439.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv(\"flights.dat\", dtype={'sched_dep_time': 'f8', 'sched_arr_time': 'f8'})\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_cols = [\n",
    "    'openflights_id',\n",
    "    'name',\n",
    "    'city',\n",
    "    'country',\n",
    "    'iata',\n",
    "    'icao',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'altitude',\n",
    "    'tz',\n",
    "    'dst',\n",
    "    'tz_olson',\n",
    "    'type',\n",
    "    'airport_dsource'\n",
    "]\n",
    "\n",
    "airports = pd.read_csv(\"airports.dat\", names=airports_cols)\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "It looks like the departure and arrival were read in a floating-point numbers.  Write two functions, `extract_hour` and `extract_mins` that converts military time to hours and minutes, respectively. Hint: You may want to use modular arithmetic and integer division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hour(time):\n",
    "    \"\"\"\n",
    "    Extracts hour information from military time.\n",
    "    \n",
    "    Args: \n",
    "        time (float64): array of time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): array of input dimension with hour information.  \n",
    "          Should only take on integer values in 0-23\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def extract_hour(time):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return time // 100 \n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mins(time):\n",
    "    \"\"\"\n",
    "    Extracts minute information from military time\n",
    "    \n",
    "    Args: \n",
    "        time (float64): array of time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): array of input dimension with hour information.  \n",
    "          Should only take on integer values in 0-59\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def extract_hour(time):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return time % 100 \n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "Using your two functions above, filter the `flights` data for flights that departed 15 or more minutes later than scheduled.  You need not worry about flights that were delayed to the next day for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_minofday(time):\n",
    "    \"\"\"\n",
    "    Converts military time to minute of day\n",
    "    \n",
    "    Args:\n",
    "        time (float64): array of time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): array of input dimension with minute of day\n",
    "    \n",
    "    Example: 1:03pm is converted to 783.0\n",
    "    >>> convert_to_minofday(1303.0)\n",
    "    783.0\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "def calc_time_diff(x, y):\n",
    "    \"\"\"\n",
    "    Calculates delay times y - x\n",
    "    \n",
    "    Args:\n",
    "        x (float64): array of scheduled time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "        y (float64): array of same dimensions giving actual time\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): array of input dimension with delay time\n",
    "    \"\"\"\n",
    "    \n",
    "    scheduled = ...\n",
    "    actual = ...\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def convert_to_minofday(time):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    return extract_hour(time) * 60 + extract_mins(time) \n",
    "\n",
    "def calc_time_diff(x, y):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    scheduled = convert_to_minofday(x) \n",
    "    actual = convert_to_minofday(y)\n",
    "    \n",
    "    return actual - scheduled \n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = ...\n",
    "delayed15 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "delay = calc_time_diff(flights['sched_dep_time'], flights['actual_dep_time'])\n",
    "delayed15 = flights[delay > 15] \n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "Using your answer from question 2, find the full name of every destination city with a flight from SFO or OAK that was delayed by 15 or more minutes.  The airport codes used in `flights` are IATA codes.  Sort the cities alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_airports = ...\n",
    "delayed_destinations = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "delayed_airports = airports['iata'].isin(delayed15['destination'])\n",
    "delayed_destinations = airports.loc[delayed_airports, 'city'].sort_values()\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Find the tail number of the top ten planes, measured by number of destinations the plane flew to in January.  You may find `drop_duplicates` and `sort_values` helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "top10 = (\n",
    "    flights[['tailnum', 'destination']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('tailnum')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "Add a new column to `airports` called `sfo_arr_delay_avg` that contains information about the average delay time in January from SFO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "flights['delay'] = calc_time_diff(flights['sched_dep_time'], flights['actual_dep_time'])\n",
    "avg_delay = (\n",
    "    flights[flights['origin']=='SFO']\n",
    "    .groupby('destination')\n",
    "    .agg({'delay': np.mean})\n",
    ")\n",
    "airports = pd.merge(airports, avg_delay, how='inner', left_on='iata', right_index=True)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our non-null results.  Do any of the delay values catch your eye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "airports.loc[pd.notnull(airports['delay']), ['name', 'city', 'delay']]\\\n",
    "    .sort_values('delay', ascending=False)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 Done!\n",
    "\n",
    "The materials for this lab have been sourced from [Data 100 at UC Berkeley](http://www.ds100.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
