{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Nearest Neighbors ###\n",
    "In this lab, we'll play around with nearest-neighbor metrics and work on the problem of using nearest neighbors for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following cell, don't modify it:\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance in Multiple Dimensions ###\n",
    "We know how to compute euclidean distance in 2-dimensional space. If we have a point at coordinates $(x_0,y_0)$ and another at $(x_1,y_1)$, the distance between them is\n",
    "\n",
    "$$D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2}.$$\n",
    "\n",
    "In 3-dimensional space, the points are $(x_0, y_0, z_0)$ and $(x_1, y_1, z_1)$, and the formula for the distance between them is\n",
    "\n",
    "$$\n",
    "D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2 + (z_0-z_1)^2}\n",
    "$$\n",
    "\n",
    "In $n$-dimensional space, things are a bit harder to visualize, but I think you can see how the formula generalized: we sum up the squares of the differences between each individual coordinate, and then take the square root of that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: Complete the following distance function that computes the euclidean distance between two $n$-dimensional points `point1` and `point2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point1, point2):\n",
    "    \"\"\"Returns the distance between point1 and point2\n",
    "    where each argument is an array \n",
    "    consisting of the coordinates of the point\"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def distance(point1, point2):\n",
    "    \"\"\"Returns the distance between point1 and point2\n",
    "    where each argument is an array \n",
    "    consisting of the coordinates of the point\"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Classification\n",
    "\n",
    "Let's use this on a [wine dataset](https://archive.ics.uci.edu/ml/datasets/Wine). The table `wine` contains the chemical composition of 178 different Italian wines. The classes are the grape species, called cultivars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('wine.csv')\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three classes but let's just see whether we can tell Class 1 apart from the other two. Let's create a new column, `ClassOne`, with value `1` if the class is `1` and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For converting Class to binary\n",
    "def is_one(x):\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "wine['Class'] = wine['Class'].apply(lambda x: is_one(x))\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two wines are both in Class 1. Let's find the distance between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Find the distance between Wine 0 and Wine 1 in the `wine` table using the `distance` function defined in question 1. \n",
    "\n",
    "*Hint*: To access a row $i$ in a dataframe `df`, use `df.iloc[i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "distance(wine.iloc[0], wine.iloc[1])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: The last wine in the table is of Class 0. Find its distance from the first wine.\n",
    "\n",
    "*Hint*: You could use the row number, or a negative index to access the last element of the dataframe with the `iloc` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "distance(wine.iloc[0], wine.iloc[-1])\n",
    "</pre>\n",
    "OR\n",
    "<pre>\n",
    "distance(wine.iloc[0], wine.iloc[177])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a bit bigger! Let's do some visualization to see if Class 1 really looks different from Class 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Create a scatter plot of `Flavanoids` vs. `Alcohol` and color the points based on `Class`. \n",
    "\n",
    "*Hint*: Use the `colormap='viridis'` paramter to get a better color differentiator than black and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatterplot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "wine.plot.scatter('Flavanoids', 'Alcohol', c='Class', colormap='viridis')\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yellow points (Class 1) are almost entirely separate from the purple ones. That is one indication of why the distance between two Class 1 wines would be smaller than the distance between wines of two different classes. Let's see the compare with `Alcalinity of Ash` and `Ash` as attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Create a scatter plot of `Alcalinity of Ash` vs. `Ash` and color the points based on `Class`. \n",
    "\n",
    "*Hint*: Use the `colormap='viridis'` paramter to get a better color differentiator than black and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatterplot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "wine.plot.scatter('Alcalinity of Ash', 'Ash', c='Class', colormap='viridis')\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for some pairs the picture is more murky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Create a scatter plot of `Magnesium` vs. `Total Phenols` and color the points based on `Class`. \n",
    "\n",
    "*Hint*: Use the `colormap='viridis'` paramter to get a better color differentiator than black and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatterplot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "wine.plot.scatter('Magnesium', 'Total Phenols', c='Class', colormap='viridis')\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can implement a classifier based on all of the attributes. After that, we'll see how accurate it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Plan for the Implementation ###\n",
    "It's time to write some code to implement the classifier.  The input is a `point` that we want to classify.  The classifier works by finding the $k$ nearest neighbors of `point` from the training set.  So, our approach will go like this:\n",
    "\n",
    "1. Find the closest $k$ neighbors of `point`, i.e., the $k$ wines from the training set that are most similar to `point`.\n",
    "\n",
    "2. Look at the classes of those $k$ neighbors, and take the majority vote to find the most-common class of wine.  Use that as our predicted class for `point`.\n",
    "\n",
    "So that will guide the structure of our Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Step 1 ###\n",
    "To implement the first step for the kidney disease data, we had to compute the distance from each patient in the training set to `point`, sort them by distance, and take the $k$ closest patients in the training set.  \n",
    "\n",
    "That's what we did in the previous section with the point corresponding to Alice. Let's generalize that code. We'll redefine `distance` here, just for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: Complete the `all_distances` function below. The function should return an array of distances between every point in the `table` and a `new_point`\n",
    "\n",
    "*Hint*: [df.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) can be used to apply a function to every row, if you pass `axis=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function below\n",
    "def all_distances(training, new_point):\n",
    "    \"\"\"Returns an array of distances\n",
    "    between each point in the training set\n",
    "    and the new point (which is a row of attributes)\"\"\"\n",
    "    attributes = training.drop(['Class'], axis=1) # Remove the class attribute from the table\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def all_distances(training, new_point):\n",
    "    \"\"\"Returns an array of distances\n",
    "    between each point in the training set\n",
    "    and the new point (which is a row of attributes)\"\"\"\n",
    "    attributes = training.drop(['Class'], axis=1) # Remove the class attribute\n",
    "    return attributes.apply(lambda x: distance(x, new_point), axis=1)</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to test your function\n",
    "all_distances(wine, wine.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**: Complete the `closest` function below. Given a series of indexed data returned by `all_distances`, it should return the top `k` points that are closest to it.\n",
    "\n",
    "*Hint*: [series.sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.sort_values.html) will sort the values in increasing distance by default, and you can slice the resulting series by `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function below\n",
    "def closest(training, new_point, k):\n",
    "    \"\"\"Returns the top k points closest to new_point from training\"\"\"\n",
    "    distances = all_distances(training, new_point)\n",
    "    topk = ...\n",
    "    return topk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def closest(training, new_point, k):\n",
    "    \"\"\"Returns the top k points closest to new_point from training\"\"\"\n",
    "    distances = all_distances(training, new_point)\n",
    "    topk = distances.sort_values()[:k]\n",
    "    return topk\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works on our `wine` data. We'll just take the first wine and find its five nearest neighbors among all the wines. Remember that since this wine is part of the dataset, it is its own nearest neighbor. So we should expect to see it at the top of the list, followed by four others.\n",
    "\n",
    "First let's extract its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_wine = wine.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's find its 5 nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest(wine, special_wine, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! The first row is the nearest neighbor, which is itself â€“ there's a 0 in the series value as expected. \n",
    "\n",
    "The following function will allow us to see these points by index from the original table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for this function\n",
    "def show_closest_rows(table, closest_series):\n",
    "    return table.iloc[closest_series.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell below to see the closest wines\n",
    "show_closest_rows(wine, closest(wine,special_wine,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All five nearest neighbors are of Class 1, which is consistent with our earlier observation that Class 1 wines appear to be clumped together in some dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Steps 2 and 3 ###\n",
    "Next we need to take a \"majority vote\" of the nearest neighbors and assign our point the same class as the majority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: Complete the `majority` function below. Given a set of rows returned by `show_closest_rows` it should take vote on the `Class` column and return the majority (`0` or `1`)\n",
    "\n",
    "*Hint*: You can use [loc[]]() and the python built-in function `len()` to find the number of rows that match a certain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function below\n",
    "def majority(topkrows):\n",
    "    ones = ...\n",
    "    zeros = ...\n",
    "    if ones > zeros:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def majority(topkrows):\n",
    "    ones = len(topkrows.loc[topkrows['Class'] == 1])\n",
    "    zeros = len(topkrows.loc[topkrows['Class'] == 0])\n",
    "    if ones > zeros:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function here\n",
    "special_wine = wine.iloc[0]\n",
    "top5rows = show_closest_rows(wine, closest(wine,special_wine,5))\n",
    "majority(top5rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to stitch everything together. \n",
    "\n",
    "**Question 8**: Using the functions defined above, write a `classify` function that given a `training` set, and a `new_point` and a classifier parameter `k`, find the closest class to the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(training, new_point, k):\n",
    "    ...\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><button>Click here to reveal the answer!</button></summary>\n",
    "<pre>\n",
    "def classify(training, new_point, k):\n",
    "    closest_points = closest(wine, new_point, 5)\n",
    "    topkrows = show_closest_rows(wine, closest_points)\n",
    "    return majority(topkrows)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your classifier below\n",
    "special_wine = wine.iloc[0]\n",
    "classify(wine, special_wine, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change `special_wine` to be the last one in the dataset, is our classifier able to tell that it's in Class 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_wine = wine.iloc[177]\n",
    "classify(wine, special_wine, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! The classifier gets this one right too.\n",
    "\n",
    "But we don't yet know how it does with all the other wines, and in any case we know that testing on wines that are already part of the training set might be over-optimistic. We'll learn about classifier training and errors next week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for Lab 06. This lab was built from the [Data 8 textbook](https://www.inferentialthinking.com/chapters/17/4/Implementing_the_Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
